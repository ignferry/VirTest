apiVersion: v1
kind: ServiceAccount
metadata:
  name: otelcol-agent
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otelcol-agent
rules:
  - apiGroups: [""]
    resources: [
      "namespaces",
      "namespaces/status",
      "nodes",
      "nodes/spec",
      "nodes/stats",
      "pods",
      "pods/status",
      "resourcequotas",
      "replicationcontrollers",
      "replicationcontrollers/status"
    ]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["replicasets", "daemonsets", "deployments", "statefulsets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources: ["replicasets", "daemonsets", "deployments"]
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otelcol-agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otelcol-agent
subjects:
- kind: ServiceAccount
  name: otelcol-agent
  namespace: default\
---
apiVersion: v1
kind: Secret
metadata:
  name: grafana-cloud
data:
  username: FILL-WITH-USERNAME
  password: FILL-WITH-PASSWORD
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: otelcol-agent
data:
  relay: |
    extensions:
      basicauth/otlp:
        client_auth:
          username: ${env:GRAFANA_CLOUD_USERNAME}
          password: ${env:GRAFANA_CLOUD_PASSWORD}
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      k8s_observer: 
        auth_type: serviceAccount
        node: ${K8S_NODE_NAME}
        observe_pods: true
        observe_nodes: true

    exporters:
      otlphttp:
        auth:
          authenticator: basicauth/otlp
        endpoint: ${env:GRAFANA_CLOUD_OTLP_ENDPOINT}

    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            cors:
              allowed_origins:
              - http://*
              - https://*
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
      receiver_creator/kubeletstats_node:
        watch_observers: [k8s_observer]
        receivers: 
          kubeletstats:
            rule: type=="k8s.node"
            config:
              collection_interval: 10s
              auth_type: serviceAccount
              endpoint: "https://${env:K8S_NODE_NAME}:10250"
              insecure_skip_verify: true
              metric_groups:
              - node
              metrics:
                k8s.node.cpu.usage:
                  enabled: true
                k8s.node.cpu.utilization:
                  enabled: false
                k8s.node.cpu.time:
                  enabled: false
                k8s.node.memory.available:
                  enabled: true
                k8s.node.memory.usage:
                  enabled: true
                k8s.node.memory.rss:
                  enabled: false
                k8s.node.memory.working_set:
                  enabled: false
                k8s.node.memory.page_faults:
                  enabled: false
                k8s.node.memory.major_page_faults:
                  enabled: false
                k8s.node.filesystem.available:
                  enabled: false
                k8s.node.filesystem.capacity:
                  enabled: false
                k8s.node.filesystem.usage:
                  enabled: false
                k8s.node.network.io:
                  enabled: false
                k8s.node.network.errors:
                  enabled: false
                k8s.node.uptime:
                  enabled: false
      receiver_creator/kubeletstats_pod:
        watch_observers: [k8s_observer]
        receivers: 
          kubeletstats:
            rule: type=="pod"
            config:
              collection_interval: 10s
              auth_type: serviceAccount
              endpoint: "https://${env:K8S_NODE_NAME}:10250"
              insecure_skip_verify: true
              metric_groups:
              - pod
              metrics:
                k8s.pod.cpu.usage:
                  enabled: true
                k8s.pod.cpu.utilization:
                  enabled: false
                k8s.pod.cpu.time:
                  enabled: false
                k8s.pod.memory.available:
                  enabled: true
                k8s.pod.memory.usage:
                  enabled: true
                k8s.pod.cpu_limit_utilization:
                  enabled: false
                k8s.pod.cpu_request_utilization:
                  enabled: false
                k8s.pod.memory_limit_utilization:
                  enabled: false
                k8s.pod.memory_request_utilization:
                  enabled: false
                k8s.pod.memory.rss:
                  enabled: false
                k8s.pod.memory.working_set:
                  enabled: false
                k8s.pod.memory.page_faults:
                  enabled: false
                k8s.pod.memory.major_page_faults:
                  enabled: false
                k8s.pod.filesystem.available:
                  enabled: false
                k8s.pod.filesystem.capacity:
                  enabled: false
                k8s.pod.filesystem.usage:
                  enabled: false
                k8s.pod.network.io:
                  enabled: false
                k8s.pod.network.errors:
                  enabled: false
                k8s.pod.uptime:
                  enabled: false
    processors:
      batch: 
        send_batch_max_size: 400
        timeout: 15s
        send_batch_size: 200
      batch/traces:
        send_batch_max_size: 50
        timeout: 3s
        send_batch_size: 25
      metricstransform:
        transforms:
          include: .+
          match_type: regexp
          action: update
          operations:
          - action: add_label
            new_label: testrun.id
            new_value: ${env:TEST_RUN_ID}
      attributes:
        actions:
        - key: testrun.id
          value: ${env:TEST_RUN_ID}
          action: upsert
      k8sattributes:
        auth_type: serviceAccount
        filter:
          node_from_env_var: K8S_NODE_NAME
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.deployment.name
          - k8s.statefulset.name
          - k8s.daemonset.name
          - k8s.cronjob.name
          - k8s.job.name
          - k8s.node.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.pod.start_time
          - k8s.container.name
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
          - from: resource_attribute
            name: k8s.pod.name
      resource:
        attributes:
        - action: insert
          from_attribute: k8s.pod.name
          key: service.instance.id
      resource/pod:
        attributes:
        - action: insert
          from_attribute: k8s.pod.name
          key: service.instance.id
        - action: insert
          from_attribute: k8s.namespace.name
          key: service.namespace
        - action: upsert
          from_attribute: k8s.deployment.name
          key: service.name
        - action: upsert
          from_attribute: k8s.daemonset.name
          key: service.name
      resource/node:
        attributes:
        - action: insert
          from_attribute: k8s.node.name
          key: service.instance.id
      filter/namespace:
        metrics:
          include:
            match_type: strict
            resource_attributes:
            - key: k8s.namespace.name
              value: ${env:NAMESPACE_NAME}

    service:
      extensions: 
      - basicauth/otlp
      - health_check
      - k8s_observer
      pipelines:
        traces:
          receivers:
          - otlp
          - jaeger
          - zipkin
          processors:
          - k8sattributes
          - batch/traces
          exporters: 
          - otlphttp
        metrics/application:
          receivers:
          - otlp
          processors:
          - k8sattributes
          - resource
          - attributes
          - batch
          exporters:
          - otlphttp
        metrics/node:
          receivers: 
          - receiver_creator/kubeletstats_node
          processors:
          - k8sattributes
          - resource/node
          - attributes
          - batch
          exporters:
          - otlphttp
        metrics/pod:
          receivers: 
          - receiver_creator/kubeletstats_pod
          processors:
          - k8sattributes
          - filter/namespace
          - resource/pod
          - attributes
          - batch
          exporters:
          - otlphttp
        logs:
          receivers:
          - otlp
          processors:
          - k8sattributes
          - attributes
          - batch
          exporters: 
          - otlphttp
---
apiVersion: v1
kind: Service
metadata:
  name: otelcol-agent
  namespace: default
spec:
  type: ClusterIP
  ports:
    
    - name: jaeger-compact
      port: 6831
      targetPort: 6831
      protocol: UDP
    - name: jaeger-grpc
      port: 14250
      targetPort: 14250
      protocol: TCP
    - name: jaeger-thrift
      port: 14268
      targetPort: 14268
      protocol: TCP
    - name: metrics
      port: 8888
      targetPort: 8888
      protocol: TCP
    - name: otlp
      port: 4317
      targetPort: 4317
      protocol: TCP
      appProtocol: grpc
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
    - name: prometheus
      port: 9464
      targetPort: 9464
      protocol: TCP
    - name: zipkin
      port: 9411
      targetPort: 9411
      protocol: TCP
  selector:
    app.kubernetes.io/name: otelcol
  internalTrafficPolicy: Cluster
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: otelcol-agent
  labels:
    app.kubernetes.io/name: otelcol
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: otelcol
  template:
    metadata:
      labels:
        app.kubernetes.io/name: otelcol
        app.kubernetes.io/instance: otel-demo
    spec:
      serviceAccountName: otelcol-agent
      securityContext:
        {}
      containers:
        - name: opentelemetry-collector
          args:
            - --config=/conf/relay.yaml
          securityContext:
            {}
          image: "otel/opentelemetry-collector-contrib:0.99.0"
          imagePullPolicy: IfNotPresent
          ports:
            
            - name: jaeger-compact
              containerPort: 6831
              protocol: UDP
            - name: jaeger-grpc
              containerPort: 14250
              protocol: TCP
            - name: jaeger-thrift
              containerPort: 14268
              protocol: TCP
            - name: metrics
              containerPort: 8888
              protocol: TCP
            - name: otlp
              containerPort: 4317
              protocol: TCP
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
            - name: prometheus
              containerPort: 9464
              protocol: TCP
            - name: zipkin
              containerPort: 9411
              protocol: TCP
          env:
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: GOMEMLIMIT
              value: "160MiB"
            - name: K8S_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: GRAFANA_CLOUD_USERNAME
              valueFrom:
                secretKeyRef:
                  name: grafana-cloud
                  key: username
            - name: GRAFANA_CLOUD_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: grafana-cloud
                  key: password
            - name: GRAFANA_CLOUD_OTLP_ENDPOINT
              valueFrom:
                secretKeyRef:
                  name: grafana-cloud
                  key: otlp-endpoint
            - name: TEST_RUN_ID
              value: "sample-test-run"
            - name: NAMESPACE_NAME
              value: default
          livenessProbe:
            httpGet:
              path: /
              port: 13133
          readinessProbe:
            httpGet:
              path: /
              port: 13133
          resources:
            limits:
              memory: 200Mi
          volumeMounts:
            - mountPath: /conf
              name: otelcol-agent-configmap
      volumes:
        - name: otelcol-agent-configmap
          configMap:
            name: otelcol-agent
            items:
              - key: relay
                path: relay.yaml
      hostNetwork: false